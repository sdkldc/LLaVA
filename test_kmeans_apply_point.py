"""
K-means ì ìš© ì‹œì  ë¹„êµ í…ŒìŠ¤íŠ¸

before_projector vs after_projector ì„±ëŠ¥ ë° ë™ì‘ ë¹„êµ
"""

import torch
import torch.nn as nn
from llava.model.kmeans_initializer import initialize_summary_tokens_with_kmeans, kmeans_clustering


def test_kmeans_apply_point_comparison():
    """ë‘ ê°€ì§€ ì ìš© ì‹œì  ë¹„êµ"""
    print("\n" + "="*60)
    print("Test: K-means Apply Point Comparison")
    print("="*60)
    
    # ëª¨ì˜ ì„¤ì •
    num_image_tokens = 576
    vision_hidden_size = 1024  # CLIP output
    llm_hidden_size = 4096     # LLaMA hidden size
    num_summary_tokens = 8
    
    # ëª¨ì˜ MM Projector (1024 â†’ 4096)
    class MockProjector(nn.Module):
        def __init__(self):
            super().__init__()
            self.linear1 = nn.Linear(vision_hidden_size, llm_hidden_size)
            self.gelu = nn.GELU()
            self.linear2 = nn.Linear(llm_hidden_size, llm_hidden_size)
        
        def forward(self, x):
            return self.linear2(self.gelu(self.linear1(x)))
    
    mm_projector = MockProjector()
    
    # ìƒ˜í”Œ vision features
    torch.manual_seed(42)
    vision_features = torch.randn(num_image_tokens, vision_hidden_size)
    
    print("\nğŸ”§ Method 1: before_projector (ê¸°ë³¸)")
    print("   Vision Encoder â†’ K-means â†’ Centroid â†’ Projector")
    # K-means ë¨¼ì €, ê·¸ ë‹¤ìŒ í”„ë¡œì í„°
    summary_before = initialize_summary_tokens_with_kmeans(
        vision_features=vision_features,
        mm_projector=mm_projector,
        num_summary_tokens=num_summary_tokens,
        metric='cosine',
        n_iter=3,
        random_state=42
    )
    print(f"   Output shape: {summary_before.shape}")
    print(f"   Mean: {summary_before.mean():.4f}, Std: {summary_before.std():.4f}")
    
    print("\nğŸ”§ Method 2: after_projector")
    print("   Vision Encoder â†’ Projector â†’ K-means â†’ Centroid")
    # í”„ë¡œì í„° ë¨¼ì €, ê·¸ ë‹¤ìŒ K-means
    with torch.no_grad():
        # Vision featuresë¥¼ ë¨¼ì € í”„ë¡œì í„°ì— í†µê³¼
        projected_features = mm_projector(vision_features.unsqueeze(0)).squeeze(0)
        # í”„ë¡œì í„° í›„ K-means
        summary_after = kmeans_clustering(
            embeddings=projected_features,
            num_clusters=num_summary_tokens,
            metric='cosine',
            n_iter=3,
            random_state=42
        )
    print(f"   Output shape: {summary_after.shape}")
    print(f"   Mean: {summary_after.mean():.4f}, Std: {summary_after.std():.4f}")
    
    # ê²°ê³¼ ë¹„êµ
    print("\nğŸ“Š Comparison:")
    print(f"   Shape match: {summary_before.shape == summary_after.shape}")
    
    # ë‹¤ì–‘ì„± ë¹„êµ (ê° ìš”ì•½ í† í° ê°„ ê±°ë¦¬)
    def compute_diversity(tokens):
        dist_matrix = torch.cdist(tokens, tokens, p=2)
        mask = torch.eye(num_summary_tokens, dtype=torch.bool)
        return dist_matrix[~mask].mean().item()
    
    div_before = compute_diversity(summary_before)
    div_after = compute_diversity(summary_after)
    
    print(f"   Diversity (before_projector): {div_before:.4f}")
    print(f"   Diversity (after_projector): {div_after:.4f}")
    
    # ê¶Œì¥ ì‚¬í•­
    print("\nğŸ’¡ Recommendation:")
    print("   - before_projector: Vision spaceì—ì„œ ì˜ë¯¸ìˆëŠ” í´ëŸ¬ìŠ¤í„° â†’ í”„ë¡œì í„° í•™ìŠµ ë°˜ì˜")
    print("   - after_projector: LLM spaceì—ì„œ ì§ì ‘ í´ëŸ¬ìŠ¤í„° â†’ ìµœì¢… ê³µê°„ ìµœì í™”")
    print("   - ê¸°ë³¸ê°’: before_projector (í”„ë¡œì í„° í•™ìŠµ íš¨ê³¼ í™œìš©)")


def test_dimension_changes():
    """ì°¨ì› ë³€í™” ì¶”ì """
    print("\n" + "="*60)
    print("Test: Dimension Changes")
    print("="*60)
    
    num_image_tokens = 576
    vision_hidden_size = 1024
    llm_hidden_size = 4096
    num_summary_tokens = 8
    
    class MockProjector(nn.Module):
        def __init__(self):
            super().__init__()
            self.linear1 = nn.Linear(vision_hidden_size, llm_hidden_size)
            self.gelu = nn.GELU()
            self.linear2 = nn.Linear(llm_hidden_size, llm_hidden_size)
        
        def forward(self, x):
            return self.linear2(self.gelu(self.linear1(x)))
    
    mm_projector = MockProjector()
    vision_features = torch.randn(num_image_tokens, vision_hidden_size)
    
    print("\nğŸ“ before_projector workflow:")
    print(f"   1. Vision features: {vision_features.shape}")
    
    centroids = kmeans_clustering(
        embeddings=vision_features,
        num_clusters=num_summary_tokens,
        metric='cosine',
        n_iter=3,
        random_state=42
    )
    print(f"   2. K-means centroids: {centroids.shape}")
    
    with torch.no_grad():
        projected = mm_projector(centroids.unsqueeze(0)).squeeze(0)
    print(f"   3. After projector: {projected.shape}")
    
    print("\nğŸ“ after_projector workflow:")
    with torch.no_grad():
        projected_all = mm_projector(vision_features.unsqueeze(0)).squeeze(0)
    print(f"   1. Vision features: {vision_features.shape}")
    print(f"   2. After projector: {projected_all.shape}")
    
    centroids_after = kmeans_clustering(
        embeddings=projected_all,
        num_clusters=num_summary_tokens,
        metric='cosine',
        n_iter=3,
        random_state=42
    )
    print(f"   3. K-means centroids: {centroids_after.shape}")


def test_computational_cost():
    """ê³„ì‚° ë¹„ìš© ë¹„êµ"""
    print("\n" + "="*60)
    print("Test: Computational Cost")
    print("="*60)
    
    num_image_tokens = 576
    vision_hidden_size = 1024
    llm_hidden_size = 4096
    num_summary_tokens = 8
    
    class MockProjector(nn.Module):
        def __init__(self):
            super().__init__()
            self.linear1 = nn.Linear(vision_hidden_size, llm_hidden_size)
            self.gelu = nn.GELU()
            self.linear2 = nn.Linear(llm_hidden_size, llm_hidden_size)
        
        def forward(self, x):
            return self.linear2(self.gelu(self.linear1(x)))
    
    mm_projector = MockProjector()
    vision_features = torch.randn(num_image_tokens, vision_hidden_size)
    
    print("\nâš¡ Computational operations:")
    
    print("\n   before_projector:")
    print(f"      - K-means on {num_image_tokens} tokens in {vision_hidden_size}-dim")
    print(f"      - Project {num_summary_tokens} centroids: {vision_hidden_size}â†’{llm_hidden_size}")
    
    print("\n   after_projector:")
    print(f"      - Project {num_image_tokens} tokens: {vision_hidden_size}â†’{llm_hidden_size}")
    print(f"      - K-means on {num_image_tokens} tokens in {llm_hidden_size}-dim")
    
    print("\nğŸ’¡ Analysis:")
    print("   - before_projector: K-means in lower dimension â†’ faster")
    print("   - after_projector: K-means in higher dimension â†’ slower but final space")


if __name__ == "__main__":
    print("\n" + "="*60)
    print("K-MEANS APPLY POINT COMPARISON TEST")
    print("="*60)
    print("\nK-meansë¥¼ ì ìš©í•˜ëŠ” ë‘ ê°€ì§€ ì‹œì ì„ ë¹„êµí•©ë‹ˆë‹¤:")
    print("1. before_projector: Vision spaceì—ì„œ í´ëŸ¬ìŠ¤í„°ë§")
    print("2. after_projector: LLM spaceì—ì„œ í´ëŸ¬ìŠ¤í„°ë§")
    
    try:
        test_kmeans_apply_point_comparison()
        test_dimension_changes()
        test_computational_cost()
        
        print("\n" + "="*60)
        print("âœ… ALL TESTS PASSED!")
        print("="*60)
        print("\në‘ ê°€ì§€ ë°©ì‹ ëª¨ë‘ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•©ë‹ˆë‹¤.")
        print("ê¸°ë³¸ê°’ before_projectorëŠ” ë” ë¹ ë¥´ê³  í”„ë¡œì í„° í•™ìŠµì„ í™œìš©í•©ë‹ˆë‹¤.\n")
        
    except Exception as e:
        print(f"\nâŒ TEST FAILED: {e}")
        import traceback
        traceback.print_exc()
